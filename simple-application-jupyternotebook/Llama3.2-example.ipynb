{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a8bf9d0-0fe0-4603-bf66-7c5deb894dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Nov  7 00:41:08 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.183.06             Driver Version: 535.183.06   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100-PCIE-40GB          On  | 00000000:01:00.0 Off |                    0 |\n",
      "| N/A   35C    P0              36W / 250W |      0MiB / 40960MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0336d230-f406-4239-8147-979a221103e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Full response JSON:**\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"model\": \"llama3.2\",\n",
      "  \"created_at\": \"2024-11-07T00:41:18.210165784Z\",\n",
      "  \"message\": {\n",
      "    \"role\": \"assistant\",\n",
      "    \"content\": \"def fibonacci(n):\\n    \\\"\\\"\\\"\\n    This function calculates the Fibonacci sequence up to the nth number.\\n\\n    Args:\\n        n (int): The position of the Fibonacci number to be calculated.\\n\\n    Returns:\\n        list: A list containing the Fibonacci numbers from 0 to n.\\n    \\\"\\\"\\\"\\n    if n <= 0:\\n        return \\\"Input should be a positive integer.\\\"\\n    elif n == 1:\\n        return [0]\\n    elif n == 2:\\n        return [0, 1]\\n    else:\\n        fib_sequence = [0, 1]\\n        while len(fib_sequence) < n:\\n            fib_sequence.append(fib_sequence[-1] + fib_sequence[-2])\\n        return fib_sequence\"\n",
      "  },\n",
      "  \"done_reason\": \"stop\",\n",
      "  \"done\": true,\n",
      "  \"total_duration\": 913629557,\n",
      "  \"load_duration\": 41156575,\n",
      "  \"prompt_eval_count\": 40,\n",
      "  \"prompt_eval_duration\": 7000000,\n",
      "  \"eval_count\": 145,\n",
      "  \"eval_duration\": 863000000\n",
      "}\n",
      "```\n",
      "\n",
      "**Generated Code:**\n",
      "\n",
      "No content found.\n",
      "**Full response JSON:**\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"model\": \"llama3.2\",\n",
      "  \"created_at\": \"2024-11-07T00:41:20.000540523Z\",\n",
      "  \"message\": {\n",
      "    \"role\": \"assistant\",\n",
      "    \"content\": \"The \\\"God particles\\\" is a nickname given to the Higgs boson particle, which was discovered in 2012 by physicists at CERN (European Organization for Nuclear Research). The name \\\"God particle\\\" comes from physicist Brian Greene's book \\\"The Elegant Universe: Superstrings, Hidden Dimensions, and the Quest for the Ultimate Theory.\\\"\\n\\nThe Higgs boson is a fundamental particle that plays a crucial role in the Standard Model of particle physics. It is responsible for giving other particles mass by interacting with them through a process known as the Higgs field.\\n\\nThe Higgs field is like a cosmic molasses that permeates all of space, and it is this field that gives mass to fundamental particles such as quarks and electrons. The Higgs boson is the quanta of the Higgs field, meaning that it is the particle that represents the field itself.\\n\\nThe discovery of the Higgs boson confirmed a key prediction made by physicist Peter Higgs in 1964, which proposed that there was a fundamental field responsible for giving mass to particles. The discovery also provided strong evidence for the existence of supersymmetry (SUSY), a theoretical framework that proposes the existence of new particles that could help explain some of the universe's most fundamental mysteries.\\n\\nWhile the name \\\"God particle\\\" is somewhat sensational, it is worth noting that physicists do not believe that the Higgs boson has any divine or supernatural significance. Rather, its discovery is a testament to human ingenuity and the power of scientific inquiry.\"\n",
      "  },\n",
      "  \"done_reason\": \"stop\",\n",
      "  \"done\": true,\n",
      "  \"total_duration\": 1785894069,\n",
      "  \"load_duration\": 27359502,\n",
      "  \"prompt_eval_count\": 31,\n",
      "  \"prompt_eval_duration\": 5000000,\n",
      "  \"eval_count\": 305,\n",
      "  \"eval_duration\": 1752000000\n",
      "}\n",
      "```\n",
      "\n",
      "\n",
      "**Generated Text:**\n",
      "\n",
      "No content found.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Ollama API endpoint\n",
    "API_URL = \"http://130.250.171.51:11434/api/chat\"\n",
    "MODEL = \"llama3.2\"\n",
    "\n",
    "def generate_response(prompt, model=MODEL):\n",
    "    \"\"\"\n",
    "    Sends a prompt to the Ollama API and returns the response.\n",
    "    \"\"\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"stream\": False\n",
    "    }\n",
    "    \n",
    "    response = requests.post(API_URL, headers=headers, data=json.dumps(payload))\n",
    "    \n",
    "    # Check if the response is successful\n",
    "    if response.status_code == 200:\n",
    "        try:\n",
    "            # Print the full response JSON for debugging in markdown format\n",
    "            response_json = response.json()\n",
    "            print(\"**Full response JSON:**\\n\")\n",
    "            print(\"```json\")\n",
    "            print(json.dumps(response_json, indent=2))\n",
    "            print(\"```\\n\")\n",
    "            \n",
    "            # Try to retrieve the generated content\n",
    "            return response_json.get('messages', [{}])[0].get('content', \"No content found.\")\n",
    "        except (KeyError, IndexError, json.JSONDecodeError) as e:\n",
    "            print(\"Unexpected response format or error:\", e)\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"Error {response.status_code}: {response.text}\")\n",
    "        return None\n",
    "\n",
    "# Example 1: Generate code based on a prompt\n",
    "prompt_code = \"Write a Python function to calculate the Fibonacci sequence up to the nth number.\"\n",
    "code_response = generate_response(prompt_code)\n",
    "print(\"**Generated Code:**\\n\")\n",
    "print(code_response if code_response else \"_No content found._\")\n",
    "\n",
    "# Example 2: Generate text based on a prompt\n",
    "prompt_text = \"What are God Particles?\"\n",
    "text_response = generate_response(prompt_text)\n",
    "print(\"\\n**Generated Text:**\\n\")\n",
    "print(text_response if text_response else \"_No content found._\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab57776-2b6a-4cba-8c85-50a738a1cf86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
